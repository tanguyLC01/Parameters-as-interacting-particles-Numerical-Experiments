{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zvY-rO59UMjZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from numba import cuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO USE FOR COLLAB\n",
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/lib/nvidia-cuda-toolkit/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/lib/x86_64-linux-gnu/libnvvm.so\"\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "!find / -iname 'libdevice'\n",
        "!find / -iname 'libnvvm.so'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ex_I3HFHXo9",
        "outputId": "6de25ae8-bc41-40f0-8c2e-494e435cd9b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/proc/65/task/65/net’: Invalid argument\n",
            "find: ‘/proc/65/net’: Invalid argument\n",
            "/usr/local/lib/python3.11/dist-packages/nvidia/cuda_nvcc/nvvm/libdevice\n",
            "/usr/local/cuda-12.5/nvvm/libdevice\n",
            "find: ‘/proc/65/task/65/net’: Invalid argument\n",
            "find: ‘/proc/65/net’: Invalid argument\n",
            "/usr/local/lib/python3.11/dist-packages/nvidia/cuda_nvcc/nvvm/lib64/libnvvm.so\n",
            "/usr/local/cuda-12.5/nvvm/lib64/libnvvm.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AQ2v2y2LUQJG"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "d_list = [3, 5, 10] # Dimensionality\n",
        "# The number of samples is supposed to be infinite in the paper.\n",
        "a_coeff = 1\n",
        "alpha = 1\n",
        "batch_size = 50  # Batch size for training\n",
        "n_neurons = [10, 50, 1e2]\n",
        "epochs = int(1e5)  # Number of training epochs\n",
        "quench_epochs = int(1e4) # Number of training epochs for quench b\n",
        "batch_quench = 2500 # 50^2\n",
        "np.random.seed(42)\n",
        "torch.random.seed()\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_from_sphere_torch(d, n_samples, device='cuda'):\n",
        "    \"\"\"Generate n_samples points on the d-dimensional sphere of radius sqrt(d) using PyTorch.\"\"\"\n",
        "    # Sample from a Gaussian distribution\n",
        "    X = torch.randn(n_samples, d, device=device)\n",
        "    # Compute the norm of each sample\n",
        "    norms = torch.norm(X, p=2, dim=1, keepdim=True)\n",
        "    # Normalize to lie on the sphere of radius sqrt(d)\n",
        "    X = (X / norms) * torch.sqrt(torch.tensor(d, device=device))\n",
        "    return X\n",
        "\n",
        "def spherical_3_spin_torch(X, a):\n",
        "    \"\"\"Compute the 3-spin function f(x) for all samples in X using PyTorch.\"\"\"\n",
        "    n_samples = X.shape[0]\n",
        "    d = X.shape[1]\n",
        "    f_out = torch.zeros(n_samples, device=X.device)\n",
        "\n",
        "    # Vectorized computation of the 3-spin function\n",
        "    for p in range(d):\n",
        "        for q in range(d):\n",
        "            for r in range(d):\n",
        "                f_out += a[p, q, r] * X[:, p] * X[:, q] * X[:, r]\n",
        "    # Normalize by d\n",
        "    f_out /= d\n",
        "    return f_out\n",
        "\n",
        "def generate_3_spin_coefficients_torch(d, device='cuda'):\n",
        "    \"\"\"Generate random Gaussian coefficients a_pqr for the 3-spin model using PyTorch.\"\"\"\n",
        "    return torch.randn(d, d, d, device=device)"
      ],
      "metadata": {
        "id": "jRKOuQThFQTw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5sN-4x5E2GXR"
      },
      "outputs": [],
      "source": [
        "class SingleLayerPerceptron(nn.Module):\n",
        "\n",
        "  def __init__(self, n_neurons, kernel, d):\n",
        "    super(). __init__()\n",
        "    self.y_i = nn.Linear(d, n_neurons)\n",
        "    self.c_i = nn.Linear(n_neurons, 1)\n",
        "    self.out = kernel\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.out(self.y_i(x))\n",
        "    x = self.c_i(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WtVrg90qXsH6"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss(reduction='mean').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jLQgV4xPT_An"
      },
      "outputs": [],
      "source": [
        "# Step 4: Evaluate the Network\n",
        "def evaluate_network(model, a_pqr, d):\n",
        "    \"\"\"Compute the loss and signed discrepancy.\"\"\"\n",
        "    with torch.no_grad():\n",
        "      X_tensor = sample_from_sphere_torch(d, 50)\n",
        "      y_tensor = spherical_3_spin_torch(X_tensor, a_pqr).reshape(-1, 1)\n",
        "      y_pred = model(X_tensor)\n",
        "      mse = criterion(y_pred, y_tensor)  # Mean squared error\n",
        "      relative = (y_pred - y_tensor)  * (y_tensor > 0)\n",
        "      signed_discrepancy = torch.mean(relative)  # Signed discrepancy for positive f(x)\n",
        "      return mse, signed_discrepancy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "FBv1rosXXLlD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sBDUSPhLUTXb"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torch\n",
        "import time\n",
        "\n",
        "def train_model(model, d, a_pqr, batch_size=50, alpha=1):\n",
        "    n = model.c_i.in_features\n",
        "    theta = a_coeff * n ** (-2 * alpha)\n",
        "    step_size = 1e-3\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=step_size)\n",
        "\n",
        "    # Create Dataset\n",
        "    print(\"Create dataset:\")\n",
        "    t = time.time()\n",
        "    X_tensor = sample_from_sphere_torch(d, epochs * batch_size)\n",
        "    y_tensor = spherical_3_spin_torch(X_tensor, a_pqr).reshape(-1, 1)\n",
        "\n",
        "    dataset = TensorDataset(X_tensor, y_tensor)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    print(\"Time taken:\", time.time() - t)\n",
        "    print(f\"Starting the regular training: {n}, {d}\")\n",
        "\n",
        "    # Training Loop\n",
        "    t = time.time()\n",
        "    scaler = GradScaler()\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "    #  Free memory after training\n",
        "    # gc.collect()\n",
        "    # del X_tensor, y_tensor, dataset, data_loader, X_batch, y_batch, predictions, loss\n",
        "    # torch.cuda.empty_cache()  # Explicitly clear cache\n",
        "\n",
        "    print(\"Time taken:\", time.time() - t)\n",
        "    print(\"Starting the quenched dataset:\", n)\n",
        "\n",
        "    #  Create Quench Dataset\n",
        "    t = time.time()\n",
        "    batch_quench = batch_size**2\n",
        "    X_quench = sample_from_sphere_torch(d, quench_epochs * batch_quench)\n",
        "    y_quench = spherical_3_spin_torch(X_quench, a_pqr).reshape(-1, 1)\n",
        "\n",
        "    quench_dataset = TensorDataset(X_quench.reshape(quench_epochs, batch_quench, d),\n",
        "                                   y_quench.reshape(quench_epochs, batch_quench, 1))\n",
        "    quench_loader = DataLoader(quench_dataset, batch_size=batch_quench, shuffle=True)\n",
        "\n",
        "    for params in optimizer.param_groups:\n",
        "        params['lr'] = 1e-4\n",
        "\n",
        "    print(\"Time taken:\", time.time() - t)\n",
        "    print(\"Starting the quenched training:\", n)\n",
        "\n",
        "    #  Quenched Training Loop\n",
        "    t = time.time()\n",
        "    for X_batch, y_batch in quench_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "    print(\"Time taken:\", time.time() - t)\n",
        "\n",
        "    # Free memory after training\n",
        "    # gc.collect()\n",
        "    # del X_quench, y_quench, quench_dataset, quench_loader, X_batch, y_batch, outputs, loss\n",
        "    # torch.cuda.empty_cache()  # Clear GPU memory\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTFVq7LOV9oo"
      },
      "source": [
        "Train for different d and multiple n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "3Yk3z8ceUk5x",
        "outputId": "41ad3f7c-fb1b-4c86-8265-0c2d15dd97ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create dataset:\n",
            "Time taken: 0.2636685371398926\n",
            "Starting the regular training: 10, 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b295ae6dc9b7>:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "<ipython-input-9-b295ae6dc9b7>:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3aff6d106c1a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleLayerPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Evalute model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-b295ae6dc9b7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, d, a_pqr, batch_size, alpha)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "a_sample = [generate_3_spin_coefficients_torch(d_list[1]) for _  in range(3)]\n",
        "result = np.zeros((len(n_neurons), len(a_sample), 2))\n",
        "i = 0\n",
        "for n in n_neurons:\n",
        "  j = 0\n",
        "  for a in a_sample:\n",
        "    model = SingleLayerPerceptron(int(n), nn.Sigmoid(), d_list[1]).to(device)\n",
        "    model = train_model(model, d_list[1], a, batch_size=50, alpha=1)\n",
        "\n",
        "    # Evalute model\n",
        "    result[i, j, :] = list(map(lambda x: x.detach().cpu().numpy(), evaluate_network(model, a, d_list[1])))\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    j += 1\n",
        "  i += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "xFGTiSxPUThl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for i, sample in enumerate(a_sample):\n",
        "    plt.plot(n_neurons, result[:, i, 0], 'o-', label=f'Sample {i+1}')\n",
        "    #plt.plot(n_neurons, )\n",
        "plt.xscale('log')\n",
        "\n",
        "# Labeling and styling\n",
        "plt.xlabel('Number of Neurons (log scale)')\n",
        "plt.ylabel('Mean MSE')\n",
        "plt.title('Mean MSE vs Number of Neurons (Log Scale)')\n",
        "plt.grid(True, which=\"both\", ls=\"--\")  # Add grid for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gHqKRRYbQgbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for i, sample in enumerate(a_sample):\n",
        "    plt.plot(n_neurons, -result[:, i, 1], 'o-', label=f'Sample {i+1}')\n",
        "plt.xscale('log')\n",
        "\n",
        "# Labeling and styling\n",
        "plt.xlabel('Number of Neurons (log scale)')\n",
        "plt.ylabel('Mean MSE')\n",
        "plt.title('Mean MSE vs Number of Neurons (Log Scale)')\n",
        "plt.grid(True, which=\"both\", ls=\"--\")  # Add grid for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HiBPdfqqwq-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}